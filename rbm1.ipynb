{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rbm1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lchen64/C3DfMRI/blob/master/rbm1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OIXTR8yGXp7",
        "colab_type": "code",
        "outputId": "acb2debd-3f60-4b74-9d34-ce9f2c951512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2280, 0.2328, 0.9673],\n",
            "        [0.1944, 0.7836, 0.2214],\n",
            "        [0.0203, 0.0215, 0.8160],\n",
            "        [0.2839, 0.8817, 0.9098],\n",
            "        [0.8383, 0.6874, 0.3628]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EODIAqvjGXqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTjEmDVdGXqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class RBM():\n",
        "\n",
        "    def __init__(self, num_visible, num_hidden, k, learning_rate=1e-3, momentum_coefficient=0.5, weight_decay=1e-4, use_cuda=True):\n",
        "        self.num_visible = num_visible\n",
        "        self.num_hidden = num_hidden\n",
        "        self.k = k\n",
        "        self.learning_rate = learning_rate\n",
        "        self.momentum_coefficient = momentum_coefficient\n",
        "        self.weight_decay = weight_decay\n",
        "        self.use_cuda = use_cuda\n",
        "\n",
        "        self.weights = torch.randn(num_visible, num_hidden) * 0.1-\n",
        "        self.visible_bias = torch.ones(num_visible) * 0.5\n",
        "        self.hidden_bias = torch.zeros(num_hidden)\n",
        "\n",
        "        self.weights_momentum = torch.zeros(num_visible, num_hidden)\n",
        "        self.visible_bias_momentum = torch.zeros(num_visible)\n",
        "        self.hidden_bias_momentum = torch.zeros(num_hidden)\n",
        "\n",
        "        if self.use_cuda:\n",
        "            self.weights = self.weights.cuda()\n",
        "            self.visible_bias = self.visible_bias.cuda()\n",
        "            self.hidden_bias = self.hidden_bias.cuda()\n",
        "\n",
        "            self.weights_momentum = self.weights_momentum.cuda()\n",
        "            self.visible_bias_momentum = self.visible_bias_momentum.cuda()\n",
        "            self.hidden_bias_momentum = self.hidden_bias_momentum.cuda()\n",
        "\n",
        "    def sample_hidden(self, visible_probabilities):\n",
        "        hidden_activations = torch.matmul(visible_probabilities, self.weights) + self.hidden_bias\n",
        "        hidden_probabilities = self._sigmoid(hidden_activations)\n",
        "        return hidden_probabilities\n",
        "\n",
        "    def sample_visible(self, hidden_probabilities):\n",
        "        visible_activations = torch.matmul(hidden_probabilities, self.weights.t()) + self.visible_bias\n",
        "        visible_probabilities = self._sigmoid(visible_activations)\n",
        "        return visible_probabilities\n",
        "\n",
        "    def contrastive_divergence(self, input_data):\n",
        "        # Positive phase\n",
        "        positive_hidden_probabilities = self.sample_hidden(input_data)\n",
        "        positive_hidden_activations = (positive_hidden_probabilities >= self._random_probabilities(self.num_hidden)).float()\n",
        "        positive_associations = torch.matmul(input_data.t(), positive_hidden_activations)\n",
        "\n",
        "        # Negative phase\n",
        "        hidden_activations = positive_hidden_activations\n",
        "\n",
        "        for step in range(self.k):\n",
        "            visible_probabilities = self.sample_visible(hidden_activations)\n",
        "            hidden_probabilities = self.sample_hidden(visible_probabilities)\n",
        "            hidden_activations = (hidden_probabilities >= self._random_probabilities(self.num_hidden)).float()\n",
        "\n",
        "        negative_visible_probabilities = visible_probabilities\n",
        "        negative_hidden_probabilities = hidden_probabilities\n",
        "\n",
        "        negative_associations = torch.matmul(negative_visible_probabilities.t(), negative_hidden_probabilities)\n",
        "\n",
        "        # Update parameters\n",
        "        self.weights_momentum *= self.momentum_coefficient\n",
        "        self.weights_momentum += (positive_associations - negative_associations)\n",
        "\n",
        "        self.visible_bias_momentum *= self.momentum_coefficient\n",
        "        self.visible_bias_momentum += torch.sum(input_data - negative_visible_probabilities, dim=0)\n",
        "\n",
        "        self.hidden_bias_momentum *= self.momentum_coefficient\n",
        "        self.hidden_bias_momentum += torch.sum(positive_hidden_probabilities - negative_hidden_probabilities, dim=0)\n",
        "\n",
        "        batch_size = input_data.size(0)\n",
        "\n",
        "        self.weights += self.weights_momentum * self.learning_rate / batch_size\n",
        "        self.visible_bias += self.visible_bias_momentum * self.learning_rate / batch_size\n",
        "        self.hidden_bias += self.hidden_bias_momentum * self.learning_rate / batch_size\n",
        "\n",
        "        self.weights -= self.weights * self.weight_decay  # L2 weight decay\n",
        "\n",
        "        # Compute reconstruction error\n",
        "        error = torch.sum((input_data - negative_visible_probabilities)**2)\n",
        "\n",
        "        return error\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "    def _random_probabilities(self, num):\n",
        "        random_probabilities = torch.rand(num)\n",
        "\n",
        "        if self.use_cuda:\n",
        "            random_probabilities = random_probabilities.cuda()\n",
        "\n",
        "        return random_probabilities\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGmvnYNDGXqF",
        "colab_type": "code",
        "outputId": "f2730c84-73c5-44f7-98d0-2d117bb2799a",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import torch\n",
        "import torchvision.datasets\n",
        "import torchvision.models\n",
        "import torchvision.transforms\n",
        "\n",
        "\n",
        "\n",
        "########## CONFIGURATION ########## \n",
        "BATCH_SIZE = 64\n",
        "VISIBLE_UNITS = 784  # 28 x 28 images\n",
        "HIDDEN_UNITS = 784 #128\n",
        "CD_K = 2\n",
        "EPOCHS = 10\n",
        "\n",
        "DATA_FOLDER = ''#'data/mnist'\n",
        "\n",
        "CUDA = torch.cuda.is_available()\n",
        "CUDA_DEVICE = 0\n",
        "\n",
        "if CUDA:\n",
        "    torch.cuda.set_device(CUDA_DEVICE)\n",
        "\n",
        "\n",
        "########## LOADING DATASET ##########\n",
        "print('Loading dataset...')\n",
        "\n",
        "#train_dataset = torchvision.datasets.MNIST(root=DATA_FOLDER, train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "train_dataset = torchvision.datasets.MNIST(root=DATA_FOLDER, train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root=DATA_FOLDER, train=False, transform=torchvision.transforms.ToTensor(), download=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "########## TRAINING RBM ##########\n",
        "print('Training RBM...')\n",
        "\n",
        "rbm = RBM(VISIBLE_UNITS, HIDDEN_UNITS, CD_K, use_cuda=CUDA)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_error = 0.0\n",
        "\n",
        "    for batch, _ in train_loader:\n",
        "        batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
        "\n",
        "        if CUDA:\n",
        "            batch = batch.cuda()\n",
        "\n",
        "        batch_error = rbm.contrastive_divergence(batch)\n",
        "\n",
        "        epoch_error += batch_error\n",
        "\n",
        "    print('Epoch Error (epoch=%d): %.4f' % (epoch, epoch_error))\n",
        "\n",
        "\n",
        "########## EXTRACT FEATURES ##########\n",
        "print('Extracting features...')\n",
        "\n",
        "train_features = np.zeros((len(train_dataset), HIDDEN_UNITS))\n",
        "train_labels = np.zeros(len(train_dataset))\n",
        "test_features = np.zeros((len(test_dataset), HIDDEN_UNITS))\n",
        "test_labels = np.zeros(len(test_dataset))\n",
        "\n",
        "for i, (batch, labels) in enumerate(train_loader):\n",
        "    batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
        "\n",
        "    if CUDA:\n",
        "        batch = batch.cuda()\n",
        "\n",
        "    train_features[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = rbm.sample_hidden(batch).cpu().numpy()\n",
        "    train_labels[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = labels.numpy()\n",
        "\n",
        "for i, (batch, labels) in enumerate(test_loader):\n",
        "    batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
        "\n",
        "    if CUDA:\n",
        "        batch = batch.cuda()\n",
        "\n",
        "    test_features[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = rbm.sample_hidden(batch).cpu().numpy()\n",
        "    #test_visible[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = rbm.sample_visible(batch).cpu().numpy()\n",
        "    test_labels[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = labels.numpy()\n",
        "\n",
        "\n",
        "########## CLASSIFICATION ##########\n",
        "print('Classifying...')\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(train_features, train_labels)\n",
        "predictions = clf.predict(test_features)\n",
        "\n",
        "print('Result: %d/%d' % (sum(predictions == test_labels), test_labels.shape[0]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "Training RBM...\n",
            "Epoch Error (epoch=0): 3296847.5000\n",
            "Epoch Error (epoch=1): 2155368.7500\n",
            "Epoch Error (epoch=2): 1884536.3750\n",
            "Epoch Error (epoch=3): 1736148.3750\n",
            "Epoch Error (epoch=4): 1640916.1250\n",
            "Epoch Error (epoch=5): 1573921.1250\n",
            "Epoch Error (epoch=6): 1524518.1250\n",
            "Epoch Error (epoch=7): 1480032.6250\n",
            "Epoch Error (epoch=8): 1451212.8750\n",
            "Epoch Error (epoch=9): 1422088.1250\n",
            "Extracting features...\n",
            "Classifying...\n",
            "Result: 9656/10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq_WhgdSGXqI",
        "colab_type": "code",
        "outputId": "4c99829c-a2f8-4bc6-9e89-032923ace0ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(train_features[0], train_labels)\n",
        "#plt.imshow([train_dataset[1][i].numpy() for i in range(len(train_dataset[1]))])\n",
        "#train_dataset[1][0]\n",
        "#print((train_dataset[2][1]))\n",
        "plt.imshow(train_dataset[2][0].numpy()[0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8038df5cb9d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#train_dataset[1][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print((train_dataset[2][1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejUiuB_8GXqM",
        "colab_type": "code",
        "outputId": "c0ad5b8b-8a9b-4636-f8e2-47aad783bfac",
        "colab": {}
      },
      "source": [
        "vp = train_dataset[2][0].view(VISIBLE_UNITS)\n",
        "sh = rbm.sample_hidden(vp)\n",
        "sv = rbm.sample_visible(sh)\n",
        "plt.imshow(sv.reshape(28,28))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRQql8IsU6v8BczGc1NUW5BwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nG0XnsyGXqR",
        "colab_type": "code",
        "outputId": "598e47b8-3731-4eee-a996-f4b9bd03e05f",
        "colab": {}
      },
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}